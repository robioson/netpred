import torch
from torch import tensor
from peptides import Peptide
from Bio.Alphabet.IUPAC import IUPACProtein


def encode_aa(aa: str) -> tensor:
    """Retrieve the encoding vector for a one-code AA using an encoding scheme supported by the peptides library."""
    return tensor(Peptide(aa).kidera_factors(), dtype=torch.float32)


def generate_aa_encoding_table() -> tensor:
    """Build an encoding table for all 20 AAs using an encoding scheme supported by the peptides library."""
    return torch.stack(list(map(encode_aa, IUPACProtein.letters)))


# Extracted from Zvelebil et al. (1987), Table 2, and reordered to match PSSM ordering
_truth_table = tensor([[1, 0, 0, 0, 0, 1, 1, 0, 0, 0],  # Ala
                       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],  # Cys
                       [0, 0, 1, 1, 1, 1, 0, 0, 0, 0],  # Asp
                       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],  # Glu
                       [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],  # Phe
                       [1, 0, 0, 0, 0, 1, 1, 0, 0, 1],  # Gly
                       [1, 1, 0, 1, 1, 0, 0, 0, 1, 0],  # His
                       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],  # Ile
                       [1, 1, 0, 1, 1, 0, 0, 0, 0, 0],  # Lys
                       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],  # Leu
                       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # Met
                       [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],  # Asn
                       [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],  # Pro
                       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],  # Gln
                       [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],  # Arg
                       [0, 0, 0, 1, 0, 1, 1, 0, 0, 0],  # Ser
                       [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],  # Thr
                       [1, 0, 0, 0, 0, 1, 0, 1, 0, 0],  # Val
                       [1, 0, 0, 1, 0, 0, 0, 0, 1, 0],  # Trp
                       [1, 0, 0, 1, 0, 0, 0, 0, 1, 0],  # Tyr
                       ], dtype=torch.float32)

# Extracted from Fauchere et al. (1988), Table 1, reordered and columns normalised. Column 4 removed
_physical_params = tensor([[0.1378, 0.3055, 0.5098, 0.3670, 0.8000, 0.3036, 0.1125, 0.1238, 0.4101, -0.0667, 0.0000,
                            0.0000, 0.0000, 0.0000, 0.8366],
                           [0.6844, 0.4224, 0.6078, 0.5716, 0.8000, 0.5074, 0.3130, 0.3007, 0.8090, 0.8000, 0.0000,
                           0.0000, 0.0000, 0.0000, 0.6450],
                           [-0.3422, 0.3819, 0.7451, 0.6061, 0.8000, 0.5625, 0.2567, 0.3441, 0.5169, 1.0000, 0.2500,
                           1.0000, 0.0000, 1.0000, 1.0000],
                           [-0.2844, 0.3723, 0.6667, 0.7634, 0.8000, 0.4926, 0.3692, 0.4678, 0.6404, 0.4667, 0.2500,
                           1.0000, 0.0000, 1.0000, 0.9631],
                           [0.7956, 0.7017, 0.6863, 0.5908, 0.8000, 0.8958, 0.7090, 0.7290, 0.7809, 0.2000, 0.0000,
                           0.0000, 0.0000, 0.0000, 0.7575],
                           [0.0000, 0.0000, 0.0000, 0.2634, 0.5263, 0.1488, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
                           0.0000, 0.0000, 0.0000, 0.6626],
                           [0.0578, 0.7136, 0.6863, 0.6688, 0.8000, 0.8423, 0.5623, 0.5767, 0.5730, 0.5333, 0.2500,
                           0.2500, 1.0000, 0.0000, 0.4991],
                           [0.8000, 1.0000, 1.0000, 0.6292, 1.0000, 0.5193, 0.4548, 0.4950, 0.9045, -0.0667, 0.0000,
                           0.0000, 0.0000, 0.0000, 0.8453],
                           [-0.4400, 0.4511, 0.6667, 0.8811, 0.8000, 0.7247, 0.5355, 0.5903, 0.6124, 0.0000, 0.5000,
                           0.2500, 1.0000, 0.0000, 0.7504],
                           [0.7556, 0.6181, 0.9608, 0.6292, 0.8000, 0.6622, 0.4548, 0.4950, 0.5674, -0.0667, 0.0000,
                           0.0000, 0.0000, 0.0000, 0.8418],
                           [0.5467, 0.5609, 0.7647, 0.8133, 0.8000, 0.7143, 0.5403, 0.5483, 0.5843, 0.2667, 0.0000,
                           0.0000, 0.0000, 0.0000, 0.7469],
                           [-0.2667, 0.3819, 0.7451, 0.5857, 0.8000, 0.6503, 0.3276, 0.3651, 0.4494, 0.4000, 0.5000,
                           0.7500, 0.0000, 0.0000, 0.6397],
                           [0.3200, 0.6372, -0.9804, 0.5256, 0.8000, 0.6414, -2.4450, 0.3366, 1.0000, -6.6667, 0.0000,
                           0.0000, 0.0000, 0.0000, -0.1757],
                           [-0.0978, 0.3723, 0.6667, 0.7813, 0.8000, 0.5253, 0.4401, 0.4889, 0.5955, 0.3333, 0.5000,
                           0.7500, 0.0000, 0.0000, 0.7979],
                           [-0.4489, 0.5585, 0.6667, 1.0000, 0.8000, 0.9286, 0.7115, 0.7587, 0.6236, 0.2667, 1.0000,
                           0.7500, 1.0000, 0.0000, 0.7557],
                           [-0.0178, 0.3126, 0.5196, 0.5077, 0.8000, 0.4018, 0.1516, 0.1980, 0.7360, 0.7333, 0.2500,
                           0.5000, 0.0000, 0.0000, 0.6731],
                           [0.1156, 0.7232, 0.4902, 0.5256, 0.9105, 0.4717, 0.2641, 0.3218, 0.9382, 0.2667, 0.2500,
                           0.5000, 0.0000, 0.0000, 0.6801],
                           [0.5422, 0.8759, 0.7451, 0.5256, 1.0000, 0.4717, 0.3423, 0.3713, 0.9663, 0.0667, 0.0000,
                           0.0000, 0.0000, 0.0000, 0.8541],
                           [1.0000, 0.7661, 0.6863, 0.9821, 0.8000, 0.8780, 1.0000, 1.0000, 0.7416, 0.0000, 0.2500,
                           0.0000, 0.0000, 0.0000, 0.8348],
                           [0.4267, 0.7017, 0.6863, 0.6049, 0.8000, 1.0000, 0.7286, 0.8007, 0.7809, 0.2000, 0.2500,
                           0.5000, 0.0000, 0.0000, 0.7557]
                           ], dtype=torch.float32)

# Copied from Georgiev (2009), Table 7 and reordered to match PSSM ordering
_weighted_varimax = tensor([[0.281, 0.962, -1.352, 0.674, -0.320, -0.117, 0.349, -0.530, -0.558, 0.334],      # Ala
                            [1.315, -0.432, -1.217, -1.082, 0.886, -0.649, 0.125, -0.797, 0.616, -0.962],     # Cys
                            [-1.219, -0.187, -0.213, 0.039, 0.223, 0.071, -1.466, -0.268, 0.202, 0.381],      # Asp
                            [-1.526, 0.984, 0.018, 0.178, -0.147, -0.000, -1.613, -0.025, 0.413, -0.575],     # Glu
                            [1.542, 0.194, 0.887, -0.100, -0.263, 0.473, -0.043, -0.093, 1.163, 0.186],       # Phe
                            [0.076, -0.993, -1.100, 0.593, 0.208, 2.178, 0.117, 0.371, -0.131, -0.738],       # Gly
                            [-0.195, 0.284, -0.234, -1.002, 0.016, 0.121, 0.458, -0.137, 0.984, 0.386],       # His
                            [1.535, 0.106, 0.097, 0.298, -0.013, -0.345, -0.061, 0.789, 0.238, 0.503],        # Ile
                            [-1.925, 0.419, 0.720, 0.337, 0.159, 0.029, 1.142, -0.002, -0.073, -0.422],       # Lys
                            [1.344, 0.535, 0.711, 1.531, 0.025, 0.027, 0.077, -0.928, 0.119, -0.306],         # Leu
                            [0.937, 1.106, -0.579, -1.030, -0.763, 0.604, 0.238, 0.423, -0.567, 0.198],       # Met
                            [-0.999, -0.548, 0.014, -0.186, 0.482, 0.605, 0.113, -0.565, -0.020, 1.785],      # Asn
                            [-0.289, -1.234, -0.006, -0.060, -2.482, -0.530, -0.033, -0.269, 0.000, -0.168],  # Pro
                            [-1.256, 0.518, -0.304, -0.531, 0.026, -0.174, 0.071, 0.483, -0.532, -0.425],     # Gln
                            [-1.386, 0.089, 1.050, 0.073, 0.059, -0.107, 1.085, 0.224, 0.672, -0.251],        # Arg
                            [-0.543, -0.585, -0.809, 0.391, 0.531, -0.981, 0.396, -0.276, -0.783, 0.098],     # Ser
                            [-0.324, -0.455, -0.514, 0.180, 0.404, -0.714, -0.187, 0.783, 0.093, 0.062],      # Thr
                            [1.308, 0.008, -0.246, 0.672, 0.190, -0.587, -0.093, 0.898, -0.057, 0.322],       # Val
                            [0.934, -0.025, 1.556, -0.795, 0.216, 0.252, -0.304, -0.379, -1.626, -0.169],     # Trp
                            [0.389, -0.745, 1.520, -0.180, 0.566, -0.155, -0.369, 0.299, -0.155, -0.241]      # Tyr
                            ], dtype=torch.float32)


selected_encoding = _truth_table


def embed_pssm(pssm: tensor, e=selected_encoding) -> tensor:
    """Embed a PSSM of (20, l), returning (e, l), where e is the encoded dimensionality."""
    return torch.einsum('al,ae->el', pssm, e)
